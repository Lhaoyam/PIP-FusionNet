{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c442f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from transformers import AutoModelForMaskedLM\n",
    "\n",
    "  # ESM++ is a faithful implementation of ESMC (license) that allows for batching and standard Huggingface compatibility without requiring the ESM Python package. The small version corresponds to the 300 million parameter version of ESMC.\n",
    " # “This model is an approximate version of the ESM Cambrian 300M model, with fewer parameters, making it more suitable for local execution and fine-tuning.”\n",
    "    \n",
    "def getSequenceData(first_dir, file_name):\n",
    "    \"\"\"\n",
    "    Read protein sequences and their labels from a file.\n",
    "    \n",
    "    Args:\n",
    "        first_dir: Directory path\n",
    "        file_name: File name\n",
    "        \n",
    "    Returns:\n",
    "        Tuple[List[str], List[List[int]]]: Lists of sequences and labels\n",
    "    \"\"\"\n",
    "    data, label = [], []\n",
    "    path = os.path.join(first_dir, f\"{file_name}.txt\")\n",
    "\n",
    "    with open(path) as f:\n",
    "        for each in f:\n",
    "            each = each.strip()\n",
    "            if each[0] == '>':\n",
    "                # Convert label string to list of integers\n",
    "                label.append([int(char) for char in each[1:]])\n",
    "            else:\n",
    "                data.append(each)\n",
    "\n",
    "    return data, label\n",
    "\n",
    "def extract_features(model_name, sequences, pooling_type, device, batch_size=16):\n",
    "    \"\"\"\n",
    "    Extract features from protein sequences using ESMplusplus model.\n",
    "    \n",
    "    Args:\n",
    "        model_name: Name of the ESMplusplus model ('small' or 'large')\n",
    "        sequences: List of protein sequences\n",
    "        pooling_type: Type of pooling ('mean', 'max', or 'cls')\n",
    "        device: Device to run the model on\n",
    "        batch_size: Batch size for processing\n",
    "        \n",
    "    Returns:\n",
    "        torch.Tensor: Extracted features tensor\n",
    "    \"\"\"\n",
    "\n",
    "  \n",
    "    # Load model and tokenizer\n",
    "    print(f\"Loading ESMplusplus_{model_name} model...\")\n",
    "    model = AutoModelForMaskedLM.from_pretrained(f'E:/ESMplusplus_{model_name}', trust_remote_code=True, local_files_only=True)\n",
    "    tokenizer = model.tokenizer\n",
    "    \n",
    "    # Move model to specified device\n",
    "    model = model.to(device)\n",
    "    model.eval()\n",
    "    \n",
    "    # Initialize list to store features\n",
    "    all_features = []\n",
    "    \n",
    "    # Process batches\n",
    "    for i in tqdm(range(0, len(sequences), batch_size), desc=f\"Extracting {pooling_type} features\"):\n",
    "        batch = sequences[i:i+batch_size]\n",
    "        \n",
    "        # Tokenize\n",
    "        tokenized = tokenizer(batch, padding=True, return_tensors='pt')\n",
    "        tokenized = {k: v.to(device) for k, v in tokenized.items()}\n",
    "        \n",
    "        # Get features\n",
    "        with torch.no_grad():\n",
    "            output = model(**tokenized)\n",
    "            last_hidden_states = output.last_hidden_state\n",
    "        \n",
    "        # Apply pooling\n",
    "        if pooling_type == 'mean':\n",
    "            batch_features = last_hidden_states.mean(dim=1)\n",
    "        elif pooling_type == 'max':\n",
    "            batch_features = last_hidden_states.max(dim=1).values\n",
    "        elif pooling_type == 'cls':\n",
    "            batch_features = last_hidden_states[:, 0, :]\n",
    "        \n",
    "        # Move to CPU\n",
    "        all_features.append(batch_features.cpu())\n",
    "    \n",
    "    # Combine features\n",
    "    features_tensor = torch.cat(all_features, dim=0)\n",
    "    \n",
    "    # Print feature dimension information\n",
    "    print(f\"Extracted features dimension: {features_tensor.shape[1]}\")\n",
    "    \n",
    "    return features_tensor\n",
    "\n",
    "def main():\n",
    "    # Set device\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "    \n",
    "    # Create base output directory\n",
    "    base_output_dir = 'otherfeatures'\n",
    "    os.makedirs(base_output_dir, exist_ok=True)\n",
    "    \n",
    "    # Data directory\n",
    "    data_dir = 'dataset/pre'  # Adjust if needed\n",
    "    \n",
    "    # Load sequences from train, val, and test sets\n",
    "    print(\"Loading datasets...\")\n",
    "    train_sequences, _ = getSequenceData(os.path.join(data_dir, 'train'), 'train')\n",
    "    val_sequences, _ = getSequenceData(os.path.join(data_dir, 'val'), 'val')\n",
    "    test_sequences, _ = getSequenceData(os.path.join(data_dir, 'test'), 'test')\n",
    "    \n",
    "    print(f\"Loaded {len(train_sequences)} training sequences\")\n",
    "    print(f\"Loaded {len(val_sequences)} validation sequences\")\n",
    "    print(f\"Loaded {len(test_sequences)} test sequences\")\n",
    "    \n",
    "    # Define models and pooling types\n",
    "    models = ['small', 'large']\n",
    "    pooling_types = ['mean', 'max', 'cls']\n",
    "    \n",
    "    # Process each combination\n",
    "    for model_name in models:\n",
    "        for pooling_type in pooling_types:\n",
    "            feature_name = f'ESMplusplus_{model_name}_{pooling_type}'\n",
    "            output_dir = os.path.join(base_output_dir, feature_name)\n",
    "            os.makedirs(output_dir, exist_ok=True)\n",
    "            \n",
    "            print(f\"\\n=== Processing {feature_name} ===\")\n",
    "            \n",
    "            # Extract and save features for each split\n",
    "            print(\"Processing training set...\")\n",
    "            train_features = extract_features(model_name, train_sequences, pooling_type, device)\n",
    "            print(f\"Training features shape: {train_features.shape} - [samples × feature_dimension]\")\n",
    "            train_output_path = os.path.join(output_dir, f'train_{feature_name}.pt')\n",
    "            torch.save(train_features, train_output_path)\n",
    "            print(f\"Saved training features to {train_output_path}\")\n",
    "            \n",
    "            print(\"Processing validation set...\")\n",
    "            val_features = extract_features(model_name, val_sequences, pooling_type, device)\n",
    "            print(f\"Validation features shape: {val_features.shape} - [samples × feature_dimension]\")\n",
    "            val_output_path = os.path.join(output_dir, f'val_{feature_name}.pt')\n",
    "            torch.save(val_features, val_output_path)\n",
    "            print(f\"Saved validation features to {val_output_path}\")\n",
    "            \n",
    "            print(\"Processing test set...\")\n",
    "            test_features = extract_features(model_name, test_sequences, pooling_type, device)\n",
    "            print(f\"Test features shape: {test_features.shape} - [samples × feature_dimension]\")\n",
    "            test_output_path = os.path.join(output_dir, f'test_{feature_name}.pt')\n",
    "            torch.save(test_features, test_output_path)\n",
    "            print(f\"Saved test features to {test_output_path}\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
